{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xitPhlbHYuNp",
        "outputId": "56702bed-5f0e-427a-a7b7-a66eb0f2e929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Naive Bayes...\n",
            "Naive Bayes - Train Accuracy: 0.9791, Validation Accuracy: 0.9623\n",
            "Training Logistic Regression...\n",
            "Logistic Regression - Train Accuracy: 0.9670, Validation Accuracy: 0.9623\n",
            "Training SVM...\n",
            "SVM - Train Accuracy: 0.9948, Validation Accuracy: 0.9803\n",
            "\n",
            "Best Model Selected: SVM\n",
            "\n",
            "Best hyperparameters: {'clf__C': 100}\n",
            "\n",
            "Test Accuracy: 0.9731\n",
            "\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       483\n",
            "           1       0.89      0.91      0.90        75\n",
            "\n",
            "    accuracy                           0.97       558\n",
            "   macro avg       0.94      0.95      0.94       558\n",
            "weighted avg       0.97      0.97      0.97       558\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "def load_data(train_path, val_path, test_path):\n",
        "    \"\"\"\n",
        "    Loads the train, validation, and test datasets from CSV files.\n",
        "    \"\"\"\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    validation_df = pd.read_csv(val_path)\n",
        "    test_df = pd.read_csv(test_path)\n",
        "\n",
        "    # Convert text labels to numerical\n",
        "    label_mapping = {'ham': 0, 'spam': 1}\n",
        "    train_df['Label'] = train_df['Label'].map(label_mapping)\n",
        "    validation_df['Label'] = validation_df['Label'].map(label_mapping)\n",
        "    test_df['Label'] = test_df['Label'].map(label_mapping)\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Cleans text data by lowercasing, removing punctuation, and numbers.\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    return text\n",
        "\n",
        "def apply_preprocessing(df):\n",
        "    \"\"\"\n",
        "    Applies text preprocessing to the 'Message' column of a dataframe.\n",
        "    \"\"\"\n",
        "    df['Message'] = df['Message'].apply(preprocess_text)\n",
        "    return df\n",
        "\n",
        "def create_pipeline(model):\n",
        "    \"\"\"\n",
        "    Creates a machine learning pipeline with TF-IDF vectorization and the specified classifier.\n",
        "    \"\"\"\n",
        "    return Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(stop_words='english')),\n",
        "        ('clf', model)\n",
        "    ])\n",
        "\n",
        "def train_models(X_train, y_train, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Trains multiple models and selects the best performing one.\n",
        "    \"\"\"\n",
        "    models = {\n",
        "        \"Naive Bayes\": create_pipeline(MultinomialNB()),\n",
        "        \"Logistic Regression\": create_pipeline(LogisticRegression(max_iter=1000)),\n",
        "        \"SVM\": create_pipeline(SVC(kernel='linear', probability=True))\n",
        "    }\n",
        "\n",
        "    model_scores = {}\n",
        "    for name, model in models.items():\n",
        "        print(f\"Training {name}...\")\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate on train and validation sets\n",
        "        train_pred = model.predict(X_train)\n",
        "        val_pred = model.predict(X_val)\n",
        "\n",
        "        train_acc = accuracy_score(y_train, train_pred)\n",
        "        val_acc = accuracy_score(y_val, val_pred)\n",
        "\n",
        "        print(f\"{name} - Train Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
        "        model_scores[name] = val_acc\n",
        "\n",
        "    best_model_name = max(model_scores, key=model_scores.get)\n",
        "    best_model = models[best_model_name]\n",
        "    print(f\"\\nBest Model Selected: {best_model_name}\")\n",
        "    return best_model_name, best_model\n",
        "\n",
        "def fine_tune_hyperparameters(best_model_name, best_model, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Fine-tunes hyperparameters of the best selected model using Grid Search.\n",
        "    \"\"\"\n",
        "    if best_model_name == \"Logistic Regression\":\n",
        "        param_grid = {\"clf__C\": [0.01, 0.1, 1, 10]}\n",
        "    elif best_model_name == \"SVM\":\n",
        "        param_grid = {\"clf__C\": [0.01, 0.1, 1, 10, 100]}\n",
        "    else:\n",
        "        param_grid = {\"clf__alpha\": [0.01, 0.1, 1, 10]}  # Naive Bayes\n",
        "\n",
        "    grid_search = GridSearchCV(best_model, param_grid, scoring='accuracy', cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    print(f\"\\nBest hyperparameters: {grid_search.best_params_}\")\n",
        "    return best_model\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Evaluates the trained model on the test set.\n",
        "    \"\"\"\n",
        "    test_pred = model.predict(X_test)\n",
        "    test_acc = accuracy_score(y_test, test_pred)\n",
        "    test_report = classification_report(y_test, test_pred)\n",
        "\n",
        "    print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
        "    print(\"\\nTest Classification Report:\\n\", test_report)\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to execute the training pipeline.\n",
        "    \"\"\"\n",
        "    # Set working directory\n",
        "    os.chdir(\"/content/drive/MyDrive/AML_Assignments/Assignment1/\")\n",
        "\n",
        "    # Load datasets\n",
        "    train_df, validation_df, test_df = load_data(\"train.csv\", \"validation.csv\", \"test.csv\")\n",
        "\n",
        "    # Preprocess text\n",
        "    train_df = apply_preprocessing(train_df)\n",
        "    validation_df = apply_preprocessing(validation_df)\n",
        "    test_df = apply_preprocessing(test_df)\n",
        "\n",
        "\n",
        "    # Split into features and labels\n",
        "    X_train, y_train = train_df['Message'], train_df['Label']\n",
        "    X_val, y_val = validation_df['Message'], validation_df['Label']\n",
        "    X_test, y_test = test_df['Message'], test_df['Label']\n",
        "\n",
        "    # Train models and select the best\n",
        "    best_model_name, best_model = train_models(X_train, y_train, X_val, y_val)\n",
        "\n",
        "    # Fine-tune the best model\n",
        "    best_model = fine_tune_hyperparameters(best_model_name, best_model, X_train, y_train)\n",
        "\n",
        "    # Evaluate the final model on the test set\n",
        "    evaluate_model(best_model, X_test, y_test)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mMHSe4TNY9xP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}