{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1-VkKTlXVkd",
        "outputId": "673c5373-b1ad-40b2-befb-65b69b48b64b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split and saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_dataset(file_path):\n",
        "    \"\"\"\n",
        "    Loads the dataset from the given file path.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    df.columns = [\"Label\", \"Message\"]\n",
        "    df[\"Label\"] = df[\"Label\"].str.lower()  # Convert labels to lowercase for consistency\n",
        "    return df\n",
        "\n",
        "def split_dataset(df, train_size=0.8, val_size=0.1, test_size=0.1, random_state=42):\n",
        "    \"\"\"\n",
        "    Splits the dataset into train, validation, and test sets.\n",
        "    \"\"\"\n",
        "    train_df, temp_df = train_test_split(df, test_size=(1 - train_size), random_state=random_state, stratify=df[\"Label\"])\n",
        "    validation_df, test_df = train_test_split(temp_df, test_size=(test_size / (test_size + val_size)),\n",
        "                                              random_state=random_state, stratify=temp_df[\"Label\"])\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "def save_splits(train_df, validation_df, test_df, output_dir=\".\"):\n",
        "    \"\"\"\n",
        "    Saves train, validation, and test datasets to CSV files.\n",
        "    \"\"\"\n",
        "    train_df.to_csv(os.path.join(output_dir, \"train.csv\"), index=False)\n",
        "    validation_df.to_csv(os.path.join(output_dir, \"validation.csv\"), index=False)\n",
        "    test_df.to_csv(os.path.join(output_dir, \"test.csv\"), index=False)\n",
        "    print(\"Data split and saved successfully!\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to execute the data preparation pipeline.\n",
        "    \"\"\"\n",
        "    os.chdir(\"/content/drive/MyDrive/AML_Assignments/Assignment1/\")  # Change directory if needed\n",
        "    file_path = \"sms_spam_collection.csv\"\n",
        "\n",
        "    # Load and preprocess dataset\n",
        "    df = load_dataset(file_path)\n",
        "\n",
        "    # Split into train, validation, and test sets\n",
        "    train_df, validation_df, test_df = split_dataset(df)\n",
        "\n",
        "    # Save the splits\n",
        "    save_splits(train_df, validation_df, test_df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Bov75vIYair"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}