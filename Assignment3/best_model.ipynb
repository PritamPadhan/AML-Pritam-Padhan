{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mlflow in /var/data/python/lib/python3.11/site-packages (2.20.3)\n",
      "Requirement already satisfied: scikit-learn in /var/data/python/lib/python3.11/site-packages (1.5.1)\n",
      "Requirement already satisfied: xgboost in /var/data/python/lib/python3.11/site-packages (3.0.0)\n",
      "Requirement already satisfied: pandas in /var/data/python/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /var/data/python/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: mlflow-skinny==2.20.3 in /var/data/python/lib/python3.11/site-packages (from mlflow) (2.20.3)\n",
      "Requirement already satisfied: Flask<4 in /var/data/python/lib/python3.11/site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /var/data/python/lib/python3.11/site-packages (from mlflow) (3.1.5)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /var/data/python/lib/python3.11/site-packages (from mlflow) (1.14.1)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /var/data/python/lib/python3.11/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /var/data/python/lib/python3.11/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /var/data/python/lib/python3.11/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /var/data/python/lib/python3.11/site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in /var/data/python/lib/python3.11/site-packages (from mlflow) (3.10.1)\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in /var/data/python/lib/python3.11/site-packages (from mlflow) (19.0.1)\n",
      "Requirement already satisfied: scipy<2 in /var/data/python/lib/python3.11/site-packages (from mlflow) (1.15.2)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /var/data/python/lib/python3.11/site-packages (from mlflow) (2.0.38)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /var/data/python/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /var/data/python/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle<4 in /var/data/python/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /var/data/python/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (0.44.1)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /var/data/python/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /var/data/python/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /var/data/python/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /var/data/python/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (1.30.0)\n",
      "Requirement already satisfied: packaging<25 in /var/data/python/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (24.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /var/data/python/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (5.29.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in /var/data/python/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (2.10.6)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /var/data/python/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /var/data/python/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /var/data/python/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /var/data/python/lib/python3.11/site-packages (from mlflow-skinny==2.20.3->mlflow) (4.12.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /var/data/python/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /var/data/python/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /var/data/python/lib/python3.11/site-packages (from xgboost) (2.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /var/data/python/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /var/data/python/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /var/data/python/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: Mako in /var/data/python/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.9)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /var/data/python/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /var/data/python/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /var/data/python/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in /var/data/python/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /var/data/python/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /var/data/python/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /var/data/python/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /var/data/python/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /var/data/python/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /var/data/python/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /var/data/python/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /var/data/python/lib/python3.11/site-packages (from matplotlib<4->mlflow) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /var/data/python/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.1.4)\n",
      "Requirement already satisfied: six>=1.5 in /var/data/python/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /var/data/python/lib/python3.11/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: google-auth~=2.0 in /var/data/python/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (2.38.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /var/data/python/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow) (4.0.12)\n",
      "Requirement already satisfied: zipp>=3.20 in /var/data/python/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.20.3->mlflow) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /var/data/python/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (1.2.18)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /var/data/python/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (0.51b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /var/data/python/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.3->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /var/data/python/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.3->mlflow) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /var/data/python/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /var/data/python/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /var/data/python/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (2025.1.31)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /var/data/python/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (1.17.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /var/data/python/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /var/data/python/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /var/data/python/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /var/data/python/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install mlflow scikit-learn xgboost pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model.ipynb  test.csv  train.csv  validation.csv\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>understand loss gain work school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dunno lei decide lor abt leona oops tot ben go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>fps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>mum ive sent many many messages since got want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>long time remember today</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                            Message\n",
       "0      0                   understand loss gain work school\n",
       "1      0  dunno lei decide lor abt leona oops tot ben go...\n",
       "2      0                                                fps\n",
       "3      0  mum ive sent many many messages since got want...\n",
       "4      0                           long time remember today"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved splits\n",
    "train = pd.read_csv(\"train.csv\").dropna()\n",
    "validation = pd.read_csv(\"validation.csv\").dropna()\n",
    "test = pd.read_csv(\"test.csv\").dropna()\n",
    "\n",
    "# Prepare features and labels\n",
    "X_train, y_train = train[\"Message\"], train[\"Label\"]\n",
    "X_val, y_val = validation[\"Message\"], validation[\"Label\"]\n",
    "X_test, y_test = test[\"Message\"], test[\"Label\"]\n",
    "\n",
    "# Convert text data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aucpr(y_true, y_pred_proba):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "    return auc(recall, precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/02 15:07:59 INFO mlflow.tracking.fluent: Experiment with name 'Spam_Ham_Classification' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Validation AUCPR: 0.9407877292674868\n",
      "Logistic Regression - Test AUCPR: 0.9278872892006962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/02 15:08:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Validation AUCPR: 0.9393194419611289\n",
      "Random Forest - Test AUCPR: 0.9590036348815346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/02 15:08:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "/var/data/python/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [15:08:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Validation AUCPR: 0.895583971072911\n",
      "XGBoost - Test AUCPR: 0.8893258696274254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/02 15:08:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Define the models to evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "}\n",
    "\n",
    "# Start MLflow experiment\n",
    "mlflow.set_experiment(\"Spam_Ham_Classification\")\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    with mlflow.start_run():\n",
    "        # Train the model on the training set\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "        # Predict probabilities on the validation set\n",
    "        y_val_pred_proba = model.predict_proba(X_val_tfidf)[:, 1]\n",
    "\n",
    "        # Calculate AUCPR on the validation set\n",
    "        val_aucpr = calculate_aucpr(y_val, y_val_pred_proba)\n",
    "        print(f\"{model_name} - Validation AUCPR: {val_aucpr}\")\n",
    "\n",
    "        # Log validation metrics\n",
    "        mlflow.log_metric(\"Validation_AUCPR\", val_aucpr)\n",
    "\n",
    "        # Predict probabilities on the test set\n",
    "        y_test_pred_proba = model.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "        # Calculate AUCPR on the test set\n",
    "        test_aucpr = calculate_aucpr(y_test, y_test_pred_proba)\n",
    "        print(f\"{model_name} - Test AUCPR: {test_aucpr}\")\n",
    "\n",
    "        # Log test metrics\n",
    "        mlflow.log_metric(\"Test_AUCPR\", test_aucpr)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: upset-horse-707, Validation AUCPR: 0.895583971072911, Test AUCPR: 0.8893258696274254\n",
      "Model: polite-flea-618, Validation AUCPR: 0.9393194419611289, Test AUCPR: 0.9590036348815346\n",
      "Model: learned-roo-747, Validation AUCPR: 0.9407877292674868, Test AUCPR: 0.9278872892006962\n"
     ]
    }
   ],
   "source": [
    "# Retrieve runs and print AUCPR\n",
    "experiment_id = mlflow.get_experiment_by_name(\"Spam_Ham_Classification\").experiment_id\n",
    "runs = mlflow.search_runs(experiment_id)\n",
    "\n",
    "for _, run in runs.iterrows():\n",
    "    print(f\"Model: {run['tags.mlflow.runName']}, Validation AUCPR: {run['metrics.Validation_AUCPR']}, Test AUCPR: {run['metrics.Test_AUCPR']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run ID: 715dbf3c41484cbf8809ba437963ea1a\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Get the experiment and all runs\n",
    "experiment_id = mlflow.get_experiment_by_name(\"Spam_Ham_Classification\").experiment_id\n",
    "runs = mlflow.search_runs(experiment_id)\n",
    "\n",
    "# Step 2: Select best run based on Validation AUCPR\n",
    "best_run = runs.loc[runs[\"metrics.Validation_AUCPR\"].idxmax()]\n",
    "best_run_id = best_run[\"run_id\"]\n",
    "\n",
    "print(f\"Best run ID: {best_run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded to: /home/pritam/Documents/AppliedML/Assignment3/mlruns/275965308563201778/715dbf3c41484cbf8809ba437963ea1a/artifacts/Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Specify the path where the model is saved in the run artifacts\n",
    "model_artifact_path = \"Logistic Regression\"  # replace if your model is logged under a different name\n",
    "\n",
    "# Step 4: Download it to a temporary directory\n",
    "local_path = mlflow.artifacts.download_artifacts(run_id=best_run_id, artifact_path=model_artifact_path)\n",
    "print(f\"Model downloaded to: {local_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved full pipeline as 'best_model.joblib'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/02 16:19:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Logged pipeline model to MLflow as 'Spam_Ham_Pipeline'\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Load the sklearn model from the downloaded path\n",
    "model = mlflow.sklearn.load_model(local_path)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Combine vectorizer and model into a pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", vectorizer),\n",
    "    (\"classifier\", model)\n",
    "])\n",
    "\n",
    "# Save pipeline locally\n",
    "joblib.dump(pipeline, \"best_model.joblib\")\n",
    "print(\"âœ… Saved full pipeline as 'best_model.joblib'\")\n",
    "\n",
    "# Optionally log to MLflow (inside active run or standalone)\n",
    "mlflow.sklearn.log_model(pipeline, \"Spam_Ham_Pipeline\")\n",
    "print(\"ðŸ“¦ Logged pipeline model to MLflow as 'Spam_Ham_Pipeline'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"best_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
